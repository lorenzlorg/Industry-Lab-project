{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_7PRWjRLI9U"
      },
      "source": [
        "# Scopo del notebook di Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm2hhxbxLI9Z"
      },
      "source": [
        "Lo scopo di questa parte è di selezionare la miglior famiglia di modelli e i corrispondenti iper-parametri, per poi addestrare il modello da usare nelle fasi successive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLQTbnZNLI9Z"
      },
      "source": [
        "# Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7Kav4vBNLI9a"
      },
      "outputs": [],
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hE6bTuAnLI9e"
      },
      "outputs": [],
      "source": [
        "# IMPORTAZIONE LIBRERIE\n",
        "import utils\n",
        "import datetime\n",
        "import importlib\n",
        "importlib.reload(utils) # ricarica lo script utils.py\n",
        "\n",
        "# PACCHETTI DI BASE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# SKLEARN\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NWl3HZtuLI9f"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE = 123\n",
        "SCORING = ['accuracy', 'precision', 'f1', 'recall', 'roc_auc']\n",
        "N_SPLITS = 5\n",
        "N_REPEATS = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE4HP50FLI9g"
      },
      "source": [
        "# Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vJQwn5euLI9g"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "X_train = pd.read_pickle(\"../Data/Prepared/train_prep.pkl.zip\", compression='zip')\n",
        "y_train = X_train.pop('Target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zaBwBqSCLI9h"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55f-EVrbLI9i"
      },
      "source": [
        "# Dummy Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "2iqNgs0zLI9j"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gtIAYcCMLI9j"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "clf_DUMMY = DummyClassifier(random_state=RANDOM_STATE,\n",
        "                            strategy=\"most_frequent\")\n",
        "\n",
        "# Fit del modello sui valori di training\n",
        "clf_DUMMY = clf_DUMMY.fit(X_train, y_train)\n",
        "\n",
        "time_stop = datetime.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n-gbKzUVLI9j"
      },
      "outputs": [],
      "source": [
        "time_duration_DUMMY = time_stop - now\n",
        "print(time_duration_DUMMY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK-2hFGuLI9k"
      },
      "source": [
        "## Performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "mean_test_accuracy_DUMMY = 0\n",
        "mean_test_precision_DUMMY = 0\n",
        "mean_test_f1_DUMMY = 0\n",
        "mean_test_recall_DUMMY = 0\n",
        "mean_test_roc_auc_DUMMY = 0.5"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qUd5oHlDLI9k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi0WwGpSLI9k"
      },
      "source": [
        "# Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qzd-GZ8MLI9l"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fypHuSMxLI9l"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "clf_LOG_REG = LogisticRegression(random_state=RANDOM_STATE)\n",
        "\n",
        "# Impostazione dei parametri del modello per la GridSearchCV\n",
        "tuned_parameters_LOG_REG = [\n",
        "  {'penalty': ['l1'],\n",
        "   'C':[0.001, .009, 0.01, .09, 1, 5, 10, 25],\n",
        "   'solver': ['liblinear', 'saga']},\n",
        "  {'penalty': ['l2'],\n",
        "   'C':[0.001, .009, 0.01, .09, 1, 5, 10, 25],\n",
        "   'solver': ['lbfgs', 'sag', 'newton-cg']},\n",
        " ]\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=N_SPLITS,\n",
        "                             n_repeats=N_REPEATS,\n",
        "                             random_state=RANDOM_STATE)\n",
        "\n",
        "grid_clf_LOG_REG = GridSearchCV(clf_LOG_REG,\n",
        "                            param_grid = tuned_parameters_LOG_REG,\n",
        "                            scoring = SCORING,\n",
        "                            refit='recall',\n",
        "                            cv = cv,\n",
        "                            verbose=3)\n",
        "\n",
        "\n",
        "# Fit del modello sui valori di training\n",
        "grid_clf_LOG_REG = grid_clf_LOG_REG.fit(X_train, y_train)\n",
        "\n",
        "grid_clf_LOG_REG.best_params_\n",
        "\n",
        "time_stop = datetime.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "h93t6B91LI9m"
      },
      "outputs": [],
      "source": [
        "time_duration_LOG_REG = time_stop - now\n",
        "print(time_duration_LOG_REG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj1Ge3-7LI9m"
      },
      "source": [
        "## Performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "testing_metrics_LOG_REG = pd.DataFrame(grid_clf_LOG_REG.cv_results_).sort_values(by=['rank_test_recall'])[['mean_test_accuracy', 'mean_test_precision', 'mean_test_f1', 'mean_test_recall', 'mean_test_roc_auc', 'rank_test_accuracy', 'rank_test_precision', 'rank_test_f1', 'rank_test_recall', 'rank_test_roc_auc']]\n",
        "testing_metrics_LOG_REG"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mmYLmS4zLI9n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "mean_test_accuracy_LOG_REG, mean_test_precision_LOG_REG, mean_test_f1_LOG_REG, mean_test_recall_LOG_REG, mean_test_roc_auc_LOG_REG = utils.metrics(testing_metrics_LOG_REG)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UjUk8KifLI9n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "23aVZFN0LI9n"
      },
      "outputs": [],
      "source": [
        "# best_score_LOG_REG = grid_clf_LOG_REG.best_score_\n",
        "# best_score_LOG_REG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSdGPw3vLI9o"
      },
      "source": [
        "# Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "L9uEE3EULI9o"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ClynJCItLI9-"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "clf_LIN_DISC = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Impostazione dei parametri del modello per la GridSearchCV\n",
        "tuned_parameters_LDA = [\n",
        "  {},\n",
        " ]\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=N_SPLITS,\n",
        "                             n_repeats=N_REPEATS,\n",
        "                             random_state=RANDOM_STATE)\n",
        "\n",
        "grid_clf_LIN_DISC = GridSearchCV(clf_LIN_DISC,\n",
        "                            param_grid = tuned_parameters_LDA,\n",
        "                            scoring = SCORING,\n",
        "                            refit='recall',\n",
        "                            cv = cv,\n",
        "                            verbose=3)\n",
        "\n",
        "# Fit del modello sui valori di training\n",
        "grid_clf_LIN_DISC = grid_clf_LIN_DISC.fit(X_train, y_train)\n",
        "\n",
        "time_stop = datetime.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EZHLp_4GLI9_"
      },
      "outputs": [],
      "source": [
        "time_duration_LDA = time_stop - now\n",
        "print(time_duration_LDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7MVXdUjLI9_"
      },
      "source": [
        "## Performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# pd.DataFrame(grid_clf_LIN_DISC.cv_results_)\n",
        "\n",
        "testing_metrics_LIN_DISC = pd.DataFrame(grid_clf_LIN_DISC.cv_results_).sort_values(by=['rank_test_recall'])[['mean_test_accuracy', 'mean_test_precision', 'mean_test_f1', 'mean_test_recall', 'mean_test_roc_auc', 'rank_test_accuracy', 'rank_test_precision', 'rank_test_f1', 'rank_test_recall', 'rank_test_roc_auc']]\n",
        "testing_metrics_LIN_DISC"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "btkGxXxCLI9_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "mean_test_accuracy_LIN_DISC, mean_test_precision_LIN_DISC, mean_test_f1_LIN_DISC, mean_test_recall_LIN_DISC, mean_test_roc_auc_LIN_DISC = utils.metrics(testing_metrics_LIN_DISC)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DXTv5DiMLI-A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# best_score_LIN_DISC = grid_clf_LIN_DISC.best_score_\n",
        "# best_score_LIN_DISC"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5lzmzFI2LI-A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu8DAhGHLI-A"
      },
      "source": [
        "# K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TPJsD3qjLI-A"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "x7A3B28NLI-A"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "clf_KNN = KNeighborsClassifier()\n",
        "\n",
        "# Impostazione dei parametri del modello per la GridSearchCV\n",
        "tuned_parameters_KNN = [\n",
        "  {'n_neighbors': [3, 5, 11, 19],\n",
        "   'weights': ['uniform', 'distance'],\n",
        "   'metric': ['euclidean', 'manhattan']}\n",
        " ]\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=N_SPLITS,\n",
        "                             n_repeats=N_REPEATS,\n",
        "                             random_state=RANDOM_STATE)\n",
        "\n",
        "grid_clf_KNN = GridSearchCV(clf_KNN,\n",
        "                            param_grid = tuned_parameters_KNN,\n",
        "                            scoring = SCORING,\n",
        "                            refit='recall',\n",
        "                            cv = cv,\n",
        "                            verbose=3)\n",
        "\n",
        "# Fit del modello sui valori di training\n",
        "grid_clf_KNN = grid_clf_KNN.fit(X_train, y_train)\n",
        "\n",
        "time_stop = datetime.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CreYAv2qLI-B"
      },
      "outputs": [],
      "source": [
        "time_duration_KNN = time_stop - now\n",
        "print(time_duration_KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MYa3_a_LI-B"
      },
      "source": [
        "## Performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "testing_metrics_KNN = pd.DataFrame(grid_clf_KNN.cv_results_).sort_values(by=['rank_test_recall'])[['mean_test_accuracy', 'mean_test_precision', 'mean_test_f1', 'mean_test_recall', 'mean_test_roc_auc', 'rank_test_accuracy', 'rank_test_precision', 'rank_test_f1', 'rank_test_recall', 'rank_test_roc_auc']]\n",
        "testing_metrics_KNN"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CWvlroEHLI-B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "mean_test_accuracy_KNN, mean_test_precision_KNN, mean_test_f1_KNN, mean_test_recall_KNN, mean_test_roc_auc_KNN = utils.metrics(testing_metrics_KNN)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LJyBPb3oLI-B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# best_score_KNN = grid_clf_KNN.best_score_  # è quello che ha rank test recall pari a 1\n",
        "# best_score_KNN"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zFNRm9e6LI-B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYBmonPbLI-C"
      },
      "source": [
        "# Decision tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "2_VkRkeDLI-C"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IoJsb5JULI-C"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "clf_DEC_TREE = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "\n",
        "# Impostazione dei parametri del modello per la GridSearchCV\n",
        "tuned_parameters_DEC_TREE = [\n",
        "  {'criterion': ['gini', 'entropy'],\n",
        "   'max_depth': [2,4,6,8,10,12]}\n",
        " ]\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=N_SPLITS,\n",
        "                             n_repeats=N_REPEATS,\n",
        "                             random_state=RANDOM_STATE)\n",
        "\n",
        "grid_clf_DEC_TREE = GridSearchCV(clf_DEC_TREE,\n",
        "                            param_grid = tuned_parameters_DEC_TREE,\n",
        "                            scoring = SCORING,\n",
        "                            refit='recall',\n",
        "                            cv = cv,\n",
        "                            verbose=3)\n",
        "\n",
        "# Fit del modello sui valori di training\n",
        "grid_clf_DEC_TREE = grid_clf_DEC_TREE.fit(X_train, y_train)\n",
        "\n",
        "time_stop = datetime.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Nz9mH41KLI-C"
      },
      "outputs": [],
      "source": [
        "time_duration_DEC_TREE = time_stop - now\n",
        "print(time_duration_DEC_TREE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf7DDMWeLI-C"
      },
      "source": [
        "## Performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# pd.DataFrame(grid_clf_DEC_TREE.cv_results_)\n",
        "\n",
        "testing_metrics_DEC_TREE = pd.DataFrame(grid_clf_DEC_TREE.cv_results_).sort_values(by=['rank_test_recall'])[['mean_test_accuracy', 'mean_test_precision', 'mean_test_f1', 'mean_test_recall', 'mean_test_roc_auc', 'rank_test_accuracy', 'rank_test_precision', 'rank_test_f1', 'rank_test_recall', 'rank_test_roc_auc']]\n",
        "testing_metrics_DEC_TREE"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "U0NdyolwLI-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "mean_test_accuracy_DEC_TREE, mean_test_precision_DEC_TREE, mean_test_f1_DEC_TREE, mean_test_recall_DEC_TREE, mean_test_roc_auc_DEC_TREE = utils.metrics(testing_metrics_DEC_TREE)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m1SnVipVLI-D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TNEXltYwLI-D"
      },
      "outputs": [],
      "source": [
        "# best_score_DEC_TREE = grid_clf_DEC_TREE.best_score_\n",
        "# best_score_DEC_TREE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WQoAUnPLI-D"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2KPgeRRLI-D"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3_Yf4fVqLI-D"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "clf_RAND_FOR = RandomForestClassifier(random_state=RANDOM_STATE)\n",
        "\n",
        "# Impostazione dei parametri del modello per la GridSearchCV\n",
        "tuned_parameters_RAND_FOR = [\n",
        "  {'n_estimators': [200, 500],\n",
        "   'max_features': ['auto', 'sqrt', 'log2'],\n",
        "   'max_depth' : [4,5,6,7,8],\n",
        "   'criterion' :['gini', 'entropy']}\n",
        " ]\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=N_SPLITS,\n",
        "                             n_repeats=N_REPEATS,\n",
        "                             random_state=RANDOM_STATE)\n",
        "\n",
        "grid_clf_RAND_FOR = GridSearchCV(clf_RAND_FOR,\n",
        "                            param_grid = tuned_parameters_RAND_FOR,\n",
        "                            scoring = SCORING,\n",
        "                            refit='recall',\n",
        "                            cv = cv,\n",
        "                            verbose=3)\n",
        "\n",
        "# Fit del modello sui valori di training\n",
        "grid_clf_RAND_FOR = grid_clf_RAND_FOR.fit(X_train, y_train)\n",
        "\n",
        "time_stop = datetime.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iqQiAK4ALI-D"
      },
      "outputs": [],
      "source": [
        "time_duration_RAND_FOR = time_stop - now\n",
        "print(time_duration_RAND_FOR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp04BCVjLI-E"
      },
      "source": [
        "## Performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "testing_metrics_RAND_FOR = pd.DataFrame(grid_clf_RAND_FOR.cv_results_).sort_values(by=['rank_test_recall'])[['mean_test_accuracy', 'mean_test_precision', 'mean_test_f1', 'mean_test_recall', 'mean_test_roc_auc', 'rank_test_accuracy', 'rank_test_precision', 'rank_test_f1', 'rank_test_recall', 'rank_test_roc_auc']]\n",
        "testing_metrics_RAND_FOR"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G59TvKRTLI-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "mean_test_accuracy_RAND_FOR, mean_test_precision_RAND_FOR, mean_test_f1_RAND_FOR, mean_test_recall_RAND_FOR, mean_test_roc_auc_RAND_FOR = utils.metrics(testing_metrics_RAND_FOR)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "D3XM_GtgLI-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "W2W7CYhiLI-E"
      },
      "outputs": [],
      "source": [
        "# best_score_RAND_FOR = grid_clf_RAND_FOR.best_score_\n",
        "# best_score_RAND_FOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5adG-PTLI-E"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-QKjjm3LI-E"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sv05ZWIkLI-E"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "clf_NB = GaussianNB()\n",
        "\n",
        "# Impostazione dei parametri del modello per la GridSearchCV\n",
        "tuned_parameters_NB = [\n",
        "  {'var_smoothing': np.logspace(0,-9, num=100)}\n",
        " ]\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=N_SPLITS,\n",
        "                             n_repeats=N_REPEATS,\n",
        "                             random_state=RANDOM_STATE)\n",
        "\n",
        "grid_clf_NB = GridSearchCV(clf_NB,\n",
        "                           param_grid = tuned_parameters_NB,\n",
        "                           scoring = SCORING,\n",
        "                           refit= 'recall',\n",
        "                           cv = cv,\n",
        "                           verbose=3)\n",
        "\n",
        "# Fit del modello sui valori di training\n",
        "grid_clf_NB = grid_clf_NB.fit(X_train, y_train)\n",
        "\n",
        "time_stop = datetime.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "m1b_RpfULI-F"
      },
      "outputs": [],
      "source": [
        "time_duration_NB = time_stop - now\n",
        "print(time_duration_NB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjjd-4m0LI-F"
      },
      "source": [
        "## Performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "testing_metrics_NB = pd.DataFrame(grid_clf_NB.cv_results_).sort_values(by=['rank_test_recall'])[['mean_test_accuracy', 'mean_test_precision', 'mean_test_f1', 'mean_test_recall', 'mean_test_roc_auc', 'rank_test_accuracy', 'rank_test_precision', 'rank_test_f1', 'rank_test_recall', 'rank_test_roc_auc']]\n",
        "testing_metrics_NB"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pADRbRXPLI-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "mean_test_accuracy_NB, mean_test_precision_NB, mean_test_f1_NB, mean_test_recall_NB, mean_test_roc_auc_NB = utils.metrics(testing_metrics_NB)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xd4QQwbrLI-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8sy7nd76LI-F"
      },
      "outputs": [],
      "source": [
        "# best_score_NB = grid_clf_NB.best_score_\n",
        "# best_score_NB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTuVLLNQLI-G"
      },
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M3xm-94LI-G"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "361cyY0YLI-G"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "clf_SVM = SVC(random_state=RANDOM_STATE,\n",
        "              probability=True)\n",
        "\n",
        "# Impostazione dei parametri del modello per la GridSearchCV\n",
        "tuned_parameters_SVM = [\n",
        "  {'C': [0.1,1, 10, 100],\n",
        "   'gamma': [0.0001,0.001,0.1,1],\n",
        "   'kernel': ['rbf', 'sigmoid']\n",
        "   }]\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=N_SPLITS,\n",
        "                             n_repeats=N_REPEATS,\n",
        "                             random_state=RANDOM_STATE)\n",
        "\n",
        "grid_clf_SVM = GridSearchCV(clf_SVM,\n",
        "                            param_grid = tuned_parameters_SVM,\n",
        "                            scoring = SCORING,\n",
        "                            refit='recall',\n",
        "                            cv = cv,\n",
        "                            verbose=3)\n",
        "\n",
        "# Fit del modello sui valori di training\n",
        "grid_clf_SVM = grid_clf_SVM.fit(X_train, y_train)\n",
        "\n",
        "time_stop = datetime.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QZC3Rn-aLI-G"
      },
      "outputs": [],
      "source": [
        "time_duration_SVM = time_stop - now\n",
        "print(time_duration_SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jNRoBDELI-G"
      },
      "source": [
        "## Performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "testing_metrics_SVM = pd.DataFrame(grid_clf_SVM.cv_results_).sort_values(by=['rank_test_recall'])[['mean_test_accuracy', 'mean_test_precision', 'mean_test_f1', 'mean_test_recall', 'mean_test_roc_auc', 'rank_test_accuracy', 'rank_test_precision', 'rank_test_f1', 'rank_test_recall', 'rank_test_roc_auc']]\n",
        "testing_metrics_SVM"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "o9aIuUGPLI-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "mean_test_accuracy_SVM, mean_test_precision_SVM, mean_test_f1_SVM, mean_test_recall_SVM, mean_test_roc_auc_SVM = utils.metrics(testing_metrics_SVM)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UTiD87nYLI-H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1YsIeKwXLI-H"
      },
      "outputs": [],
      "source": [
        "# best_score_SVM = grid_clf_SVM.best_score_\n",
        "# best_score_SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFKTp919LI-H"
      },
      "source": [
        "# Riepilogo risultati modelli\n",
        "Creazione di una tabella riassuntiva dei migliori risultati ottenuti in termini di parametri che ciascun modello utilizza e in termini di performance di accuracy, precision, recall, F1-score.\n",
        "Decisione del modello finale da utilizzare che poi dovrà essere implementato nella fase di testing. Salvataggio del modello."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULvw3OtDLI-H"
      },
      "source": [
        "## Tabella riassuntiva delle metriche"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "models_names = ['Dummy Classifier',\n",
        "               'Logistic Regression',\n",
        "               'Linear Discriminant Analysis',\n",
        "               'KNN',\n",
        "               'Decision Tree',\n",
        "               'Random Forest',\n",
        "               'Naive Bayes',\n",
        "               'Support Vector Machine']\n",
        "\n",
        "accuracy = [mean_test_accuracy_DUMMY,\n",
        "            mean_test_accuracy_LOG_REG,\n",
        "            mean_test_accuracy_LIN_DISC,\n",
        "            mean_test_accuracy_KNN,\n",
        "            mean_test_accuracy_DEC_TREE,\n",
        "            mean_test_accuracy_RAND_FOR,\n",
        "            mean_test_accuracy_NB,\n",
        "            mean_test_accuracy_SVM]\n",
        "\n",
        "precision = [mean_test_precision_DUMMY,\n",
        "             mean_test_precision_LOG_REG,\n",
        "             mean_test_precision_LIN_DISC,\n",
        "             mean_test_precision_KNN,\n",
        "             mean_test_precision_DEC_TREE,\n",
        "             mean_test_precision_RAND_FOR,\n",
        "             mean_test_precision_NB,\n",
        "             mean_test_precision_SVM]\n",
        "\n",
        "f1 = [mean_test_f1_DUMMY,\n",
        "      mean_test_f1_LOG_REG,\n",
        "      mean_test_f1_LIN_DISC,\n",
        "      mean_test_f1_KNN,\n",
        "      mean_test_f1_DEC_TREE,\n",
        "      mean_test_f1_RAND_FOR,\n",
        "      mean_test_f1_NB,\n",
        "      mean_test_f1_SVM]\n",
        "\n",
        "recall = [mean_test_recall_DUMMY,\n",
        "          mean_test_recall_LOG_REG,\n",
        "          mean_test_recall_LIN_DISC,\n",
        "          mean_test_recall_KNN,\n",
        "          mean_test_recall_DEC_TREE,\n",
        "          mean_test_recall_RAND_FOR,\n",
        "          mean_test_recall_NB,\n",
        "          mean_test_recall_SVM]\n",
        "\n",
        "roc_auc = [mean_test_roc_auc_DUMMY,\n",
        "           mean_test_roc_auc_LOG_REG,\n",
        "           mean_test_roc_auc_LIN_DISC,\n",
        "           mean_test_roc_auc_KNN,\n",
        "           mean_test_roc_auc_DEC_TREE,\n",
        "           mean_test_roc_auc_RAND_FOR,\n",
        "           mean_test_roc_auc_NB,\n",
        "           mean_test_roc_auc_SVM]\n",
        "\n",
        "time_duration = [time_duration_DUMMY,\n",
        "                time_duration_LOG_REG,\n",
        "                time_duration_LDA,\n",
        "                time_duration_KNN,\n",
        "                time_duration_DEC_TREE,\n",
        "                time_duration_RAND_FOR,\n",
        "                time_duration_NB,\n",
        "                time_duration_SVM]\n",
        "\n",
        "# Creazione della tabella dei risultati\n",
        "df_result = pd.DataFrame(list(zip(models_names,\n",
        "                                  recall,\n",
        "                                  precision,\n",
        "                                  f1,\n",
        "                                  accuracy,\n",
        "                                  roc_auc,\n",
        "                                  time_duration)),\n",
        "               columns =['models_names',\n",
        "                         'Recall',\n",
        "                         'Precision',\n",
        "                         'F1',\n",
        "                         'Accuracy',\n",
        "                         'AUC',\n",
        "                         'time_duration'])\n",
        "\n",
        "\n",
        "df_result = df_result.set_index('models_names')\n",
        "df_result = df_result.sort_values(by=['Recall', 'Accuracy'] , ascending = False)\n",
        "df_result = df_result.round(decimals = 2)\n",
        "\n",
        "print(df_result)\n",
        "\n",
        "# Salvataggio dell'output\n",
        "df_result.to_csv(r'../Models/models_metrics_cropping_ordered.csv', index=True)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-qGl3XRALI-H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQipMFa3LI-I"
      },
      "source": [
        "# Models persistence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "N48uyB1iLI-I"
      },
      "outputs": [],
      "source": [
        "# salvataggio modelli\n",
        "\n",
        "utils.pickle_dump(clf_DUMMY,  \"dummy.pkl\")\n",
        "utils.pickle_dump(grid_clf_LOG_REG,  \"log_reg.pkl\")\n",
        "utils.pickle_dump(grid_clf_LIN_DISC, \"linear_discriminant_analysis.pkl\")\n",
        "utils.pickle_dump(grid_clf_KNN,      \"knn.pkl\")\n",
        "utils.pickle_dump(grid_clf_DEC_TREE, \"decision_tree.pkl\")\n",
        "utils.pickle_dump(grid_clf_RAND_FOR, \"random_forest.pkl\")\n",
        "utils.pickle_dump(grid_clf_NB,       \"naive_bayes.pkl\")\n",
        "utils.pickle_dump(grid_clf_SVM,      \"support_vector_machine.pkl\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}